import openai
import faiss
import numpy as np
import json
from openai import OpenAI
import config

SCHEMA_FILE = "schema_descriptions.txt"
INDEX_FILE = "schema_index.faiss"
LOOKUP_FILE = "schema_lookup.json"
EMBEDDING_MODEL = "text-embedding-3-small"


def load_schema_chunks() -> list[str]:
    with open(SCHEMA_FILE, "r", encoding="utf-8") as f:
        raw = f.read()
    return [chunk.strip() for chunk in raw.split("\n\n") if chunk.strip()]


client = OpenAI(api_key=config.openai_api_key)


def get_embeddings(texts: list[str]) -> list[list[float]]:
    response = client.embeddings.create(model=EMBEDDING_MODEL, input=texts)
    return [r.embedding for r in response.data]


def build_faiss_index(vectors: list[list[float]]) -> faiss.IndexFlatL2:
    dim = len(vectors[0])
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(vectors).astype("float32"))
    return index


def save_index(index: faiss.IndexFlatL2, filename: str):
    faiss.write_index(index, filename)


def save_lookup(mapping: dict[int, str], filename: str):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(mapping, f, indent=2)


def main():
    print("ğŸ”„ Loading schema...")
    schema_chunks = load_schema_chunks()

    print("ğŸ” Generating embeddings...")
    embeddings = get_embeddings(schema_chunks)

    print("ğŸ“¦ Building FAISS index...")
    index = build_faiss_index(embeddings)

    print(f"ğŸ’¾ Saving FAISS index to {INDEX_FILE}")
    save_index(index, INDEX_FILE)

    print(f"ğŸ’¾ Saving schema lookup to {LOOKUP_FILE}")
    lookup = {i: chunk for i, chunk in enumerate(schema_chunks)}
    save_lookup(lookup, LOOKUP_FILE)

    print("âœ… Done! You can now query the schema with FAISS.")


if __name__ == "__main__":
    main()
